{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be done in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to perform sentimental analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will be using twitter dataset as training data and crawled realtime tweets for testing. \n",
    "\n",
    "The Ground truth is 1 for positive tweet and 0 for negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few examples of positive and negative tweets are:\n",
    "\n",
    "**Few Positive Tweets: **\n",
    "1.  @Msdebramaye I heard about that contest! Congrats girl!!\n",
    "2. UNC!!! NCAA Champs!! Franklin St.: I WAS THERE!! WILD AND CRAZY!!!!!! Nothing like it...EVER http://tinyurl.com/49955t3\n",
    "\n",
    "**Few Negative Tweets:**\n",
    "1. no more taking Irish car bombs with strange Australian women who can drink like rockstars...my head hurts.\n",
    "2. Just had some bloodwork done. My arm hurts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "https://www.kaggle.com/c/twitter-sentiment-analysis2/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: (2 marks)\n",
    "\n",
    "The first exercise is cleaning the tweets.\n",
    "Perform preprocessing as required.\n",
    "\n",
    "Complete the functon : preprocess_tweets \n",
    "\n",
    "Input or Arguement to the function : tweet as a string \n",
    "\n",
    "Return value: processed tweet as string \n",
    "\n",
    "Hint: Use regular expressions\n",
    "* convert the all the cases into lower case\n",
    "  + look at lower()\n",
    "* Replace any urls with the word \"URL\"\n",
    "  + Hint : \n",
    "      - re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',\"Tweet\") (re is python regular expression package)\n",
    "* convert the username to \"AT_USER\", consider any word that starts with @ as user name\n",
    "  + Hint : \n",
    "      - re.sub('@[^\\s]+','AT_USER',\"Tweet\")\n",
    "* Remove multiple whitespaces with a single white space\n",
    "  + Hint :\n",
    "      - re.sub('[\\s]+', ' ', tweet)\n",
    "* Replace hashtag words (#word) with just the words (word)\n",
    "  + Hint : \n",
    "      - re.sub(r'#([^\\s]+)', r'\\1', \"tweet\")\n",
    "      \n",
    "* TEST CASE :\n",
    "    + given the tweet \"@V_DEL_ROSSI: Me         #dragging myself to the gym https://t.co/cOjM0mBVeY\"\n",
    "    + output should be \"AT_USER me dragging myself to the gym URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:16:37.343616Z",
     "start_time": "2018-06-30T14:16:37.336703Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "# Operating System\n",
    "import os\n",
    "# Regular Expression\n",
    "import re\n",
    "# nltk packages\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "# Basic Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "# PCA Package\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT_USER me dragging myself to the gym URL\n"
     ]
    }
   ],
   "source": [
    "def preprocess_tweets(tweet):\n",
    "    tweet=tweet.lower()\n",
    "    tweet = re.sub('((www.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    tweet=re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    tweet=re.sub('[\\s]+', ' ', tweet)\n",
    "    tweet=re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    tweet=re.sub('&lt;','',tweet)#xml tag\n",
    "    tweet=re.sub('&amp;','',tweet)\n",
    "    tweet=re.sub(':o','smile',tweet) #replace smileys with good or bad emotion\n",
    "    tweet=re.sub(':-\\|','speechless',tweet)\n",
    "    tweet=re.sub('[.!,-]+', '', tweet)\n",
    "    return tweet\n",
    "\n",
    "print(preprocess_tweets(\"@V_DEL_ROSSI: Me #dragging myself to the gym https://t.co/cOjM0mBVeY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>i missed the new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 smile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>omgaga im sooo im gunna cry i've been at thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me t_t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                        is so sad for my apl friend\n",
       "1       2          0                      i missed the new moon trailer\n",
       "2       3          1                         omg its already 7:30 smile\n",
       "3       4          0    omgaga im sooo im gunna cry i've been at thi...\n",
       "4       5          0                i think mi bf is cheating on me t_t"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('twitter_train.csv',encoding='latin-1',converters={'SentimentText':preprocess_tweets})\n",
    "pw=pd.read_csv('positive-words.txt').values\n",
    "nw=pd.read_csv('negative-words.txt').values\n",
    "\n",
    "stopWords = pd.read_csv('stopwords.txt').values\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "vocabulary = set([])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: (3 marks)\n",
    "\n",
    "Tokenize the processed tweets to make a tweet into a list of words and make sure that no punctuations are returned. so that it can be used in the next steps to represent the tweet as a feature vector. Remove the Stops words, if necessary\n",
    "\n",
    "Complete the functon : word_tokenizer \n",
    "\n",
    "Input or Arguement to the function : processed tweet\n",
    "\n",
    "Return value: list of words without any punctuations\n",
    "\n",
    "TEST CASE :\n",
    "\n",
    "Given an input :\n",
    "    \"Neither Man, nor machine can replace its creator. really?.\"\n",
    "    \n",
    "Result : \n",
    "    ['neither', 'man', 'nor', 'machine', 'replace', 'creator', 'hahaha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:10:31.107306Z",
     "start_time": "2018-06-29T15:10:31.097419Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_tokenizer(tweet):\n",
    "    words = re.findall(r'(\\b[A-Za-z][a-z]{2,15}\\b)', tweet)\n",
    "    words = [ stemmer.stem(word.lower()) for word in words if not word.lower() in stopWords]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-29c45f6f96da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(data.values.shape[0]):\n",
    "    words= word_tokenizer(data.values[i][2])\n",
    "    for word in words:\n",
    "          vocabulary.add(word)\n",
    "vocabularyList=list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add postive words count, negative wourd count, neutral, and tweet (label)\n",
    "voclength=len(vocabulary)\n",
    "fvlength=voclength+4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: (5 marks)\n",
    "\n",
    "Using the list of words from the above the step, \n",
    "* represent the tweet as a feature vector using bag of words/Word2vec\n",
    "\n",
    "Hint : counts of postive/negative/neutral words as three features can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:15:36.672042Z",
     "start_time": "2018-06-29T15:15:36.666906Z"
    }
   },
   "outputs": [],
   "source": [
    "def getfeaturevector(tokenized_tweet,sentiment):\n",
    "    feature_vector=np.zeros(fvlength)\n",
    "    for word in tokenized_tweet: \n",
    "        if vocabularyList.index(word) !=-1:\n",
    "            feature_vector[vocabularyList.index(word)]+=1\n",
    "        flag=0\n",
    "        for i in range(len(pw)):\n",
    "            if word == pw[i][0]:\n",
    "                feature_vector[voclength]+=1\n",
    "                flag=1\n",
    "        for i in range(len(nw)):\n",
    "            if word == nw[i][0]:\n",
    "                feature_vector[voclength+1]+=1\n",
    "                flag=-1\n",
    "        if flag==0:\n",
    "            feature_vector[voclength+2]+=1\n",
    "        feature_vector[voclength+3]=sentiment\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaldata=[]\n",
    "for i in range(data.values.shape[0]):\n",
    "    finaldata.append(getfeaturevector(word_tokenizer(data.values[i][2]),data.values[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: (Marks : 5 ) \n",
    "\n",
    "\n",
    "Load the given training data and use the above functions you created to process, to tokenise and to get feature vector.\n",
    "\n",
    "Considering the feature vector as input to the classifier, Train a classifier to classify the sentiment of the tweet correctly.\n",
    "\n",
    "Divide the training data into two sets, to validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print\n",
    "# Your Code Hereimport random\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "def randomize():\n",
    "    TRAIN_TEST_RATIO = 0.8\n",
    "    data = finaldata\n",
    "    #print(data)\n",
    "    for one in data:\n",
    "        #print(one)\n",
    "        if random.random() < TRAIN_TEST_RATIO:\n",
    "            train.append(one)\n",
    "        else:\n",
    "            test.append(one)\n",
    "    print (test[:10])\n",
    "    \n",
    "randomize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import collections\n",
    "def dist(a, b):\n",
    "    sqSum = 0\n",
    "    for i in np.arange( len(a)):\n",
    "        sqSum += (a[i] - b[i]) ** 2\n",
    "    return math.sqrt(sqSum)\n",
    "# ------------------------------------------------ #\n",
    "# We are assuming that the label is the last field #\n",
    "# If not, munge the data to make it so!            #\n",
    "# ------------------------------------------------ #\n",
    "def kNN(k, train, given):\n",
    "    distances = []\n",
    "    for t in train:\n",
    "        distance=(dist(t[:-1], given), str(int(t[-1])))\n",
    "        #print(distance)\n",
    "        distances.append(distance)\n",
    "    distances.sort()\n",
    "    return distances[:k]\n",
    "\n",
    "def kNN_classify(k, train, given):\n",
    "    tally = collections.Counter()\n",
    "    #print(tally)\n",
    "    for nn in kNN(k, train, given):\n",
    "        tally.update(nn[-1])\n",
    "    return tally.most_common(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_accuracy(Kvalue):\n",
    "    num = 0\n",
    "    print(\"calculating accuracy\")\n",
    "    for t in test:\n",
    "        prediction = kNN_classify(Kvalue, train, t)[0]\n",
    "        #print(\"prediction, label is\", prediction, t[134])\n",
    "        if (int(prediction) == int(t[index])):\n",
    "            num += 1\n",
    "        #print(kNN_classify(5, train, t)[0], t[-1])\n",
    "    #print(num/len(test))\n",
    "    return (num/len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_accuracy(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: (Marks : 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter crawling using tweepy\n",
    "\n",
    "Use tweepy to get the tweets on real time, which is used as test data for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter account\n",
    "\n",
    "Create a twitter account if you don't have one by going to the link given below:\n",
    "\n",
    "https://twitter.com/i/flow/signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy: tweepy is the python client for the official Twitter API.\n",
    "Install it using following pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /anaconda3/lib/python3.6/site-packages (3.6.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: requests>=2.11.1 in /anaconda3/lib/python3.6/site-packages (from tweepy) (2.18.4)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.0.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2018.4.16)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets need to be gathered so as to perform Sentiment analysis on those tweets. They can be fetched from Twitter using the Twitter API. \n",
    "\n",
    "In order to fetch tweets through Twitter API, one needs to register an App through their twitter account. Follow these steps for the same:\n",
    "<ul>\n",
    "<li>Open the link given below to create a App through the twitter account.\n",
    "    https://apps.twitter.com\n",
    "<li>click the button: ‚ÄòCreate New App‚Äô\n",
    "<li>Fill the application details. You can leave the callback url field empty.\n",
    "<li>Once the app is created, you will be redirected to the app page.\n",
    "<li>Open the ‚ÄòKeys and Access Tokens‚Äô tab.\n",
    "<li>Copy ‚ÄòConsumer Key‚Äô, ‚ÄòConsumer Secret‚Äô, ‚ÄòAccess token‚Äô and ‚ÄòAccess Token Secret‚Äô.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:04.892431Z",
     "start_time": "2018-06-29T14:11:04.881562Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replace with your ‚ÄòConsumer Key‚Äô, ‚ÄòConsumer Secret‚Äô, ‚ÄòAccess token‚Äô and ‚ÄòAccess Token Secret‚Äô below. \n",
    "\n",
    "consumer_key = \"sjqCktpagvR4NjTsUR3DcA7pp\"\n",
    "consumer_secret = \"dqxiWPhqt7n7uR0tGqA18bPCRsXxtEPVNg3HmOtfmzjjjMEXwa\"\n",
    "access_token =  \"968060979681681408-kTK6GHKeBRr3oyEalq3NwQKtC9Vn4fS\"\n",
    "access_secret = \"pICNG5EIzlBwf0vmSLCitRmtloKr1J1Hmd6w8JixWDmKU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to authenticate your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:07.156485Z",
     "start_time": "2018-06-29T14:11:06.815300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "api = tweepy.API(auth)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy Cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code gives the search results from twitter for the search string passed to the keyword arguement \"q\" in the tweepy.Cursor. The number passed to the items method of tweepy.Cursor indicates that it gives 100 such tweets, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:18:19.093637Z",
     "start_time": "2018-06-29T14:18:07.691456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Lilia_Ciciolla: Another great Friday night in #FortLauderdale supporting @HendersonHlth at @BankofAmerica #StarlightMusicals in partner‚Ä¶\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t‚Ä¶\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "Bank of America Museums On Us Program https://t.co/NZ3PEw0Go3\n",
      "6 U.S. banks finance ICE detention centers: @BankofAmerica @jpmorgan @BNPParibas @SunTrust @usbank &amp; @WellsFargo pr‚Ä¶ https://t.co/x0wNYGDyEJ\n",
      "Happy Pride! Today I get to walk in Pride as the majority. To me that is so powerful &amp; I know together as a communi‚Ä¶ https://t.co/SCtwrq1Yvy\n",
      "RT @Triggered1776: Sunoco has fired #PoolPatrolPeter for racial profiling. Can we get @BankofAmerica to fire an openly racist employee next‚Ä¶\n",
      "Oh the places you can see for free this weekend!@thebrucemuseum @MattatuckMuseum @fairfieldmuseum @TheAldrich https://t.co/vQoDTkrpLh\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames Great to see the effort and the celebration!\n",
      "RT @BankofAmerica: When we win, we win together. üèÖ That's what makes the @2018USAGames so special. From athletes to volunteers, let‚Äôs work‚Ä¶\n",
      "Sunoco has fired #PoolPatrolPeter for racial profiling. Can we get @BankofAmerica to fire an openly racist employee‚Ä¶ https://t.co/ztBAgeXXxx\n",
      "@amandamkeeney @theGibbesmuseum @BankofAmerica I‚Äôve been waiting for a Charleston museum offer. üòÄThanks, Amanda!\n",
      "RT @AnneMuyiwa: @samswey @deray Sickening! We deal with this daily. I was @BankofAmerica where I was asked to wait in line for a Caucasian‚Ä¶\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t‚Ä¶\n",
      "RT @AnneMuyiwa: @samswey @deray Sickening! We deal with this daily. I was @BankofAmerica where I was asked to wait in line for a Caucasian‚Ä¶\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "@BankofAmerica how can you restrict my card and not allow for easy access to make it available... like I am not goi‚Ä¶ https://t.co/Dw0oSS5tRj\n",
      "RT @mindythefarmer: If you could describe @BankofAmerica in two words what would it be? PREDATORY. FEES.\n",
      "@emma_jeannn @BankofAmerica When you get gas do you pay outside or do you inside to the register?\n",
      "Guys..... I‚Äôm not even joking rn..... my card info got stolen again. 3rd time in 3 months. I‚Äôm officially cancellin‚Ä¶ https://t.co/RIYkequ4cY\n",
      "RT @AnneMuyiwa: @samswey @deray Sickening! We deal with this daily. I was @BankofAmerica where I was asked to wait in line for a Caucasian‚Ä¶\n",
      "RT @BankofAmerica: Meet Tyler. This @SpecialOlympics athlete is having a blast in and out of the pool. Wish him luck at the @2018USAGames.‚Ä¶\n",
      "RT @BankofAmerica: The @SpecialOlympics @2018USAGames overflowed with love, support, and hope. The games may be over, but our commitment to‚Ä¶\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames @jacksfilms Erin in 3 years, sorry not sorry\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @WWIIMemorial: An update on a story we posted earlier this week: @BankofAmerica has credited the account of a #Texas #WWII veteran after‚Ä¶\n",
      "RT @polishprincessh: So a bank can discriminate against a gun manufacturer, however, a baker is forced to bake a cake according to the cust‚Ä¶\n",
      "@BankofAmerica I can't imagine how parents must feel being separated from their kids. Give me back my $ &amp; match it with a donation to @ACLU\n",
      "RT @Diabloojosazule: Bank of America \n",
      "Will no longer finance\n",
      "gun manufacturers\n",
      "\n",
      "No Problem;\n",
      "\n",
      "My 4 accounts will\n",
      "No longer finance \n",
      "#BankofA‚Ä¶\n",
      "I cannot handle being separated from $717 that a @BankofAmerica ATM ate at 1:56 PM MST from the Greenwood Village, CO location...which means\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "@DanielJSeco @Dodgers @BankofAmerica @YasielPuig @KSeco Rude\n",
      "@jennnaaleighh @Dodgers @BankofAmerica @YasielPuig Nah, it‚Äôs for Noah cc: @KSeco\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames I‚Äôm proud of you Erin , I know you will do well at the game.\n",
      "@DanielJSeco @Dodgers @BankofAmerica @YasielPuig Are you going to send me it??\n",
      "RT @BankofAmerica: This year's @2018USAGames Special Olympics athletes are amazing off the field and on it. #PickUpHope https://t.co/iGRhqD‚Ä¶\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @Dinogiraldo: Thank you @FOX5Vegas &amp; @alyssadeitsch for having us on to talk about #BofAStudentLeaders. Syeda is an amazing young woman‚Ä¶\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames Both my son and his partner took Bronze in each of their respective d‚Ä¶ https://t.co/l2SXVsYXC8\n",
      "@amputeesoccer @votevets @BankofAmerica Damn, @BankofAmerica what took you so long? Glad you finally did it tho.\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "RT @sjmusart: This Saturday and Sunday is @BankofAmerica + @MerrillLynch #MuseumsOnUs first weekend, free for cardholders.! See #RiseUp!, C‚Ä¶\n",
      "RT @streetbanker: Early congrats to the 3,000+ youth from #Newark #NewJersey that will participate in Mayor @rasjbaraka Summer Youth Employ‚Ä¶\n",
      "#IDemand that @BankofAmerica gives me back the remaining cash it owes me after it's ATM ate my $2267 cash deposit.\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "@BankofAmerica I‚Äôve had a transaction denied several times and it‚Äôs saying it‚Äôs because BOA doesn‚Äôt allow internati‚Ä¶ https://t.co/RYq1OjLIqg\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "@votevets Great for @BankofAmerica ‚úäüèªüá∫üá∏‚úäüèΩ\n",
      "\n",
      "I‚Äôd much rather spend some time with Richard than #TheFakePresident !!\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t‚Ä¶\n",
      "@BankofAmerica should pay me for their bullshit wow\n",
      "@CamWohl @BankofAmerica I switched from hells Fargo to TD and have had nothing short of an incredible experience. #customerfocus\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames Good luck, Gentleman, although I'm sure you'll do wonderfully!\n",
      "I'd love nothing more than to be binge watching TV and eating fried chicken but a @BankofAmerica ATM ate the cash I‚Ä¶ https://t.co/i3sX258MkY\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t‚Ä¶\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @AnneMuyiwa: @samswey @deray Sickening! We deal with this daily. I was @BankofAmerica where I was asked to wait in line for a Caucasian‚Ä¶\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames Erin, you go girl!!!\n",
      "@pattidomm Don't need opinion of those who were ready to go under in 2008 and needed a bailout\n",
      "These idiots raise t‚Ä¶ https://t.co/i7GOzUoLuN\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "@BankofAmerica you should use our smokehouse chicken seasoning for your dye packs. It won‚Äôt come off anything!\n",
      "RT @christinecalace: #DinnerWasRuinedWhen on a #fridaynight @BankofAmerica screwed me #quantico style when their ATM ate my cash deposit an‚Ä¶\n",
      "RT @christinecalace: #VerySpecificRansomDemands how about @BankofAmerica gives me back the rest of the cash it's ATM ate at 1:56 PM today\n",
      "RT @christinecalace: Today #WasMyLastStraw @BankofAmerica After your ridiculous 10 day waiting period for the rest of my money because your‚Ä¶\n",
      "RT @christinecalace: #WWYD If you were a regular person deposting $2267 in cash at a @BankofAmerica ATM that rejects it but doesn't give yo‚Ä¶\n",
      "RT @christinecalace: My fianc√© is a #Cubs fan. Would have loved to use the money my @BankofAmerica ATM stole from me to buy him tickets for‚Ä¶\n",
      "@BankofAmerica Why do u keep closing my account. I travel 220 plus days a year! Amex, Capital One etc have no issue‚Ä¶ https://t.co/G1Vz7CTfnL\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "RT @NYCCTE: Thrilled to kick off work readiness wt @BankofAmerica @CTE_SummerSchol @JeffBarkerNY @steph_carosella @NYCMayorsFund @NYCCYE @T‚Ä¶\n",
      "Wow! What another fantastic Festival Rep performance by @FAUArtsLetters - Opening Night of Cabaret was phenomenal!‚Ä¶ https://t.co/LHloDLeTzc\n",
      "My fianc√© is a #Cubs fan. Would have loved to use the money my @BankofAmerica ATM stole from me to buy him tickets for the next Denver game\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good on you, @BankofAmerica\n",
      "\n",
      "Thank you for taking care of a man who gave so much to take care of us all\n",
      "\n",
      "This is th‚Ä¶ https://t.co/C5GeCCGoRb\n",
      "@CamWohl @BankofAmerica Damn dude, almost two days to respond? So which bank did you switch to after you closed your @BankofAmerica account?\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @CamWohl: Wow @BankofAmerica the silent treatment?! Unreal.\n",
      "RT @CamWohl: @BankofAmerica NOT COOL, BOA. NOT COOL AT ALL. @TDAmeritrade thanks for the great customer service after BOA stole my plastic.‚Ä¶\n",
      "From @SpokaneCity to the Puget Sound, so many great opportunities to enjoy the arts in Washington State! Thanks,‚Ä¶ https://t.co/sZRxGTN3dq\n",
      "@ZelleSupport If I have been using @Zelle with my PNC account, but now want to switch it to my @BankofAmerica account.  How do I do that?\n",
      "If I have been using @Zelle with my PNC account, but now want to switch it to my @BankofAmerica account.  How do I do that?\n",
      "RT @2018USAGames: A few of the companies at the #2018USAGames Journey to Employment Job Fair today!! #ChooseToInclude \n",
      "\n",
      "Thank you @Microsof‚Ä¶\n",
      "@votevets Thank You @BankofAmerica ‚ô•Ô∏è What you did was good!\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "@BankofAmerica taking toooooo long to answer the fucking phone!!!\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo‚Ä¶\n",
      "RT @TimShriver: Team @BankofAmerica #PickUpHope https://t.co/GmcNdHeTA4\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https‚Ä¶\n",
      "RT @ClintonCenter: The Clinton Center is happy to be a \"Museums on Us\" partner with @BankofAmerica! When you visit us this weekend (July 7-‚Ä¶\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t‚Ä¶\n",
      "RT @truthsearch1957: Bank of America @BankofAmerica w/Edward S Cohn &amp; Dyck O'Neal used fraud against me for a PAID In FULL #mortgage\n",
      "Now DY‚Ä¶\n",
      "RT @truthsearch1957: Bank of America @BankofAmerica w/Edward S Cohn &amp; Dyck O'Neal used fraud against me for a PAID In FULL #mortgage\n",
      "Now DY‚Ä¶\n",
      "What a fantastic week it's been in Seattle! We continue to #PickUpHope as we celebrate all @SpecialOlympics‚Ä¶ https://t.co/vRl2eVI2r8\n",
      "RT @truthsearch1957: Bank of America @BankofAmerica w/Edward S Cohn &amp; Dyck O'Neal used fraud against me for a PAID In FULL #mortgage\n",
      "Now DY‚Ä¶\n",
      "RT @truthsearch1957: Bank of America @BankofAmerica w/Edward S Cohn &amp; Dyck O'Neal used fraud against me for a PAID In FULL #mortgage\n",
      "Now DY‚Ä¶\n",
      "RT @CTE_SummerSchol: What an honor to have @ConnieVerducci speak to the CTESS cohort this morning! Connie encouraged our students to be eng‚Ä¶\n",
      "Another great Friday night in #FortLauderdale supporting @HendersonHlth at @BankofAmerica #StarlightMusicals in par‚Ä¶ https://t.co/eEaLLtH7bQ\n",
      "@BofA_Help When you're locked out of your @BankofAmerica account for no reason and the call waiting message says to‚Ä¶ https://t.co/CO6pcv5VMA\n"
     ]
    }
   ],
   "source": [
    "for i in tweepy.Cursor(api.search, q='bankofamerica', lang = 'en', full_text=True).items(100):\n",
    "    print(i._json['text'])\n",
    "    #print(myStreamListener.processTweet(i._json['text']), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also apply the preprocessing steps and obtain the feature vectors for the crawled twitter data.\n",
    "Classify the crawled tweets by passing its feature vector to the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
