{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Artificial Intelligence and Machine Learning\n",
    "## A Program by IIIT-H and TalentSprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To be done in the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this experiment is to perform sentimental analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment we will be using twitter dataset as training data and crawled realtime tweets for testing. \n",
    "\n",
    "The Ground truth is 1 for positive tweet and 0 for negative tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Few examples of positive and negative tweets are:\n",
    "\n",
    "**Few Positive Tweets: **\n",
    "1.  @Msdebramaye I heard about that contest! Congrats girl!!\n",
    "2. UNC!!! NCAA Champs!! Franklin St.: I WAS THERE!! WILD AND CRAZY!!!!!! Nothing like it...EVER http://tinyurl.com/49955t3\n",
    "\n",
    "**Few Negative Tweets:**\n",
    "1. no more taking Irish car bombs with strange Australian women who can drink like rockstars...my head hurts.\n",
    "2. Just had some bloodwork done. My arm hurts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Source\n",
    "\n",
    "https://www.kaggle.com/c/twitter-sentiment-analysis2/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: (2 marks)\n",
    "\n",
    "The first exercise is cleaning the tweets.\n",
    "Perform preprocessing as required.\n",
    "\n",
    "Complete the functon : preprocess_tweets \n",
    "\n",
    "Input or Arguement to the function : tweet as a string \n",
    "\n",
    "Return value: processed tweet as string \n",
    "\n",
    "Hint: Use regular expressions\n",
    "* convert the all the cases into lower case\n",
    "  + look at lower()\n",
    "* Replace any urls with the word \"URL\"\n",
    "  + Hint : \n",
    "      - re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',\"Tweet\") (re is python regular expression package)\n",
    "* convert the username to \"AT_USER\", consider any word that starts with @ as user name\n",
    "  + Hint : \n",
    "      - re.sub('@[^\\s]+','AT_USER',\"Tweet\")\n",
    "* Remove multiple whitespaces with a single white space\n",
    "  + Hint :\n",
    "      - re.sub('[\\s]+', ' ', tweet)\n",
    "* Replace hashtag words (#word) with just the words (word)\n",
    "  + Hint : \n",
    "      - re.sub(r'#([^\\s]+)', r'\\1', \"tweet\")\n",
    "      \n",
    "* TEST CASE :\n",
    "    + given the tweet \"@V_DEL_ROSSI: Me         #dragging myself to the gym https://t.co/cOjM0mBVeY\"\n",
    "    + output should be \"AT_USER me dragging myself to the gym URL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-30T14:16:37.343616Z",
     "start_time": "2018-06-30T14:16:37.336703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT_USER me dragging myself to the gym URL\n"
     ]
    }
   ],
   "source": [
    "import tweepy as tp\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim as ge\n",
    "import word2vec as wv\n",
    "\n",
    "tweet = \"@V_DEL_ROSSI: Me #dragging myself to the gym https://t.co/cOjM0mBVeY\"\n",
    "data = pd.read_csv(\"twitter_train.csv\", encoding='cp1252')\n",
    "def preprocess_tweets(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    tweet = re.sub('((www.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet);\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\n",
    "    return tweet\n",
    "\n",
    "tweet = preprocess_tweets(tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: (3 marks)\n",
    "\n",
    "Tokenize the processed tweets to make a tweet into a list of words and make sure that no punctuations are returned. so that it can be used in the next steps to represent the tweet as a feature vector. Remove the Stops words, if necessary\n",
    "\n",
    "Complete the functon : word_tokenizer \n",
    "\n",
    "Input or Arguement to the function : processed tweet\n",
    "\n",
    "Return value: list of words without any punctuations\n",
    "\n",
    "TEST CASE :\n",
    "\n",
    "Given an input :\n",
    "    \"Neither Man, nor machine can replace its creator. really?.\"\n",
    "    \n",
    "Result : \n",
    "    ['neither', 'man', 'nor', 'machine', 'replace', 'creator', 'hahaha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:00:25.764720Z",
     "start_time": "2018-06-29T15:00:25.752064Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-980b02a578d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopWords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "stopWords = pd.read_csv('stopwords.txt').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:10:31.107306Z",
     "start_time": "2018-06-29T15:10:31.097419Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5f588ca9f5cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtweet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\s!,.?\":;0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neither Man, nor machine can replace its creator. really?.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtokenized_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-5f588ca9f5cc>\u001b[0m in \u001b[0;36mword_tokenizer\u001b[0;34m(tweet)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtweet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'[^\\s!,.?\":;0-9]+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Neither Man, nor machine can replace its creator. really?.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokenized_tweet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "def word_tokenizer(tweet):\n",
    "    tweet=re.findall(r'[^\\s!,.?\":;0-9]+', tweet)\n",
    "    return tweet\n",
    "print(word_tokenizer(\"Neither Man, nor machine can replace its creator. really?.\"))\n",
    "tokenized_tweet = word_tokenizer(tweet)\n",
    "print(tokenized_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: (5 marks)\n",
    "\n",
    "Using the list of words from the above the step, \n",
    "* represent the tweet as a feature vector using bag of words/Word2vec\n",
    "\n",
    "Hint : counts of postive/negative/neutral words as three features can also be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T15:15:36.672042Z",
     "start_time": "2018-06-29T15:15:36.666906Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AT_USER', 'me', 'dragging', 'myself', 'to', 'the', 'gym', 'URL']\n",
      "Word2Vec(vocab=23, size=100, alpha=0.025)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"word 'gym' not in vocabulary\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-178-011eca1b3bac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgetfeaturevector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tweet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-178-011eca1b3bac>\u001b[0m in \u001b[0;36mgetfeaturevector\u001b[0;34m(tokenized_tweet)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_tweet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gym'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeature_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"word 'gym' not in vocabulary\""
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "sentence = [['Neither', 'Man', 'nor', 'machine', 'can', 'replace', 'its', 'creator', 'really']\n",
    "    ,['AT_USER', 'me', 'dragging', 'myself', 'to', 'the', 'gym', 'URL']]\n",
    "\n",
    "def getfeaturevector(tokenized_tweet):\n",
    "    print(tokenized_tweet)\n",
    "    \n",
    "    model = Word2Vec(tokenized_tweet, min_count=1)\n",
    "    print(model)\n",
    "    print(model.wv['gym'])\n",
    "    return feature_vector\n",
    "\n",
    "getfeaturevector(tokenized_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: (Marks : 5 ) \n",
    "\n",
    "\n",
    "Load the given training data and use the above functions you created to process, to tokenise and to get feature vector.\n",
    "\n",
    "Considering the feature vector as input to the classifier, Train a classifier to classify the sentiment of the tweet correctly.\n",
    "\n",
    "Divide the training data into two sets, to validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: (Marks : 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Twitter crawling using tweepy\n",
    "\n",
    "Use tweepy to get the tweets on real time, which is used as test data for the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter account\n",
    "\n",
    "Create a twitter account if you don't have one by going to the link given below:\n",
    "\n",
    "https://twitter.com/i/flow/signup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweepy: tweepy is the python client for the official Twitter API.\n",
    "Install it using following pip command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /anaconda3/lib/python3.6/site-packages (3.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.0.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.11.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in /anaconda3/lib/python3.6/site-packages (from tweepy) (1.6.8)\n",
      "Requirement already satisfied: requests>=2.11.1 in /anaconda3/lib/python3.6/site-packages (from tweepy) (2.18.4)\n",
      "Requirement already satisfied: oauthlib>=0.6.2 in /anaconda3/lib/python3.6/site-packages (from requests-oauthlib>=0.7.0->tweepy) (2.1.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /anaconda3/lib/python3.6/site-packages (from requests>=2.11.1->tweepy) (2018.4.16)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweets need to be gathered so as to perform Sentiment analysis on those tweets. They can be fetched from Twitter using the Twitter API. \n",
    "\n",
    "In order to fetch tweets through Twitter API, one needs to register an App through their twitter account. Follow these steps for the same:\n",
    "<ul>\n",
    "<li>Open the link given below to create a App through the twitter account.\n",
    "    https://apps.twitter.com\n",
    "<li>click the button: ‘Create New App’\n",
    "<li>Fill the application details. You can leave the callback url field empty.\n",
    "<li>Once the app is created, you will be redirected to the app page.\n",
    "<li>Open the ‘Keys and Access Tokens’ tab.\n",
    "<li>Copy ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’.\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:04.892431Z",
     "start_time": "2018-06-29T14:11:04.881562Z"
    }
   },
   "outputs": [],
   "source": [
    "#Replace with your ‘Consumer Key’, ‘Consumer Secret’, ‘Access token’ and ‘Access Token Secret’ below. \n",
    "\n",
    "consumer_key = \"sjqCktpagvR4NjTsUR3DcA7pp\"\n",
    "consumer_secret = \"dqxiWPhqt7n7uR0tGqA18bPCRsXxtEPVNg3HmOtfmzjjjMEXwa\"\n",
    "access_token =  \"968060979681681408-kTK6GHKeBRr3oyEalq3NwQKtC9Vn4fS\"\n",
    "access_token_secret = \"pICNG5EIzlBwf0vmSLCitRmtloKr1J1Hmd6w8JixWDmKU\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to authenticate your application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:11:07.156485Z",
     "start_time": "2018-06-29T14:11:06.815300Z"
    }
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweepy Cursor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code gives the search results from twitter for the search string passed to the keyword arguement \"q\" in the tweepy.Cursor. The number passed to the items method of tweepy.Cursor indicates that it gives 100 such tweets, if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-29T14:18:19.093637Z",
     "start_time": "2018-06-29T14:18:07.691456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @LoomiAssistant: #Banks like @jpmorgan @BankofAmerica and @WellsFargo are increasingly using #ArtificialIntelligence for corporate and r…\n",
      "#Banks like @jpmorgan @BankofAmerica and @WellsFargo are increasingly using #ArtificialIntelligence for corporate a… https://t.co/n6yH6xtIqi\n",
      "RT @NRAVikki: Tell Bank of America &amp; General Electric: Stop Funding Big Abortions Attacks On Pro-Life Centers\n",
      "\n",
      "👉 @generalelectric\n",
      "\n",
      "👉 @Banko…\n",
      "RT @FiskerOfficial: After my @BankofAmerica speech, I realized, we need to bring our Solid State battery technology to market quick!! Long…\n",
      "RT @FiskerOfficial: After my @BankofAmerica speech, I realized, we need to bring our Solid State battery technology to market quick!! Long…\n",
      "This #BANKofAMERICA in @Hyannis-Massachusetts DISCRIMINATES non customers by giving us shitty services. The bitch b… https://t.co/1IUGFNSjTS\n",
      "Bank of America, proud partner of Special Olympics https://t.co/ojBQLeiB3w\n",
      "🚀#BankofAmerica has recognized #cryptocurrency as a threat to its business. The management of the bank filed a repo… https://t.co/aPn4yELQLA\n",
      "RT @NRAVikki: Tell Bank of America &amp; General Electric: Stop Funding Big Abortions Attacks On Pro-Life Centers\n",
      "\n",
      "👉 @generalelectric\n",
      "\n",
      "👉 @Banko…\n",
      "RT @NRAVikki: Tell Bank of America &amp; General Electric: Stop Funding Big Abortions Attacks On Pro-Life Centers\n",
      "\n",
      "👉 @generalelectric\n",
      "\n",
      "👉 @Banko…\n",
      "RT @fr0gger_: Awesome!! I will receive $14.5M, I just need to provide some basic information \\o/ 😅 #bankofamerica #phishing https://t.co/tC…\n",
      "RT @Btcexpertindia: Its just a starting it will happen with many more banks 😂😂😂\n",
      "#bankofamerica Acknowledges #Cryptocurrencies as a Threat t…\n",
      "Awesome!! I will receive $14.5M, I just need to provide some basic information \\o/ 😅 #bankofamerica #phishing https://t.co/tCjK4J0Tky\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "RT @PromiseFX: This is for all Americans who dislike #XRP.\n",
      "\n",
      "Both #Ripple and #XRP are founded by Americans. Both could be Americans next bi…\n",
      "RT @PromiseFX: This is for all Americans who dislike #XRP.\n",
      "\n",
      "Both #Ripple and #XRP are founded by Americans. Both could be Americans next bi…\n",
      "RT @PromiseFX: This is for all Americans who dislike #XRP.\n",
      "\n",
      "Both #Ripple and #XRP are founded by Americans. Both could be Americans next bi…\n",
      "@JeremyWash @BankofAmerica Ok, I bite :-) Where do i find the code, and how do i get it running?\n",
      "@ignorantmusings @BankofAmerica @SpecialOlympics @2018USAGames Why? Are you concerned about your IQ?\n",
      "RT @CIOStraightTalk: #STinsights @BankofAmerica 's #CTO, @cathybessant on #technology's future in the age of #disruption, in an article by…\n",
      "@Johannes_Ernst @BankofAmerica It's time for us to start making these kinds of demands. I hope that the more of us… https://t.co/CMXFh3yTUa\n",
      "Tell Bank of America &amp; General Electric: Stop Funding Big Abortions Attacks On Pro-Life Centers\n",
      "\n",
      "👉 @generalelectric… https://t.co/w0yCrdR6mO\n",
      "RT @Btcexpertindia: #BankofAmerica accepted #Cryptocurrencies as a Threat to Their Business\n",
      "https://t.co/D7wlBGNjyh\n",
      "#cryptonews #cryptoupda…\n",
      "@BankofAmerica @SpecialOlympics @2018USAGames Yawn\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @pcfvirginia: Thank you @BankofAmerica's @Charlie74Tiger, @mlittle21 and Stephany Huckaby for sponsoring the celebration for #givelocal7…\n",
      "RT @AdvancedHPC: #AI Invasion of #WallStreet Is Reshaping @BankofAmerica’s #Currency Research https://t.co/5FCmjoVBID https://t.co/SniZ04Ig…\n",
      "RT @FiskerOfficial: After my @BankofAmerica speech, I realized, we need to bring our Solid State battery technology to market quick!! Long…\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "@dominos didnt gimmie my money back.  Its cool ima call @BankofAmerica and dispute it!!!\n",
      "A reward @BankofAmerica would be efficient customer service. Had my account 48 yrs! Husband moved his to @WellsFargo https://t.co/ewi7256Cjp\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "RT @sandra_juliachs: Team @BankofAmerica @2018USAGames we all cheer you on!!! https://t.co/UvcmKsGYGK\n",
      "RT @BankofAmerica: On 3....🎶1, 2, 3 cheer!🎶. Great way to start the morning at the @2018USAGames with the @SpecialOlympics #SOCheer team fr…\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "RT @BankofAmerica: These @SpecialOlympics athletes inspire us all. Watch them #PickUpHope for a more inclusive world at the @2018USAGames!…\n",
      "yo @BankofAmerica ... AND no one answered still #waivethoseoverdraftfees https://t.co/1rOb6JVc0e\n",
      "@Siermine15 @BankofAmerica Some of the worst suppers I've eaten\n",
      "@Glassflippers @BankofAmerica I can relate.\n",
      "RT @BankofAmerica: These @SpecialOlympics athletes inspire us all. Watch them #PickUpHope for a more inclusive world at the @2018USAGames!…\n",
      "I'm wondering why anyone still has an account at @BankofAmerica, or worse, with @wellsfargo! I had an auto-pay set… https://t.co/XQXIPEfyRA\n",
      "@Dodgers @BankofAmerica @YasielPuig I wanted this :(\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "RT @BankofAmerica: Proud to support Erin on her once-in-a-lifetime journey to the @SpecialOlympics @2018USAGames in Seattle. #PickUpHope fo…\n",
      "@BankofAmerica hello, I paid in full my credit card. Why I have to Pay interest? If I owe 3000$, and pay 3000$ befo… https://t.co/hfVMAgHa1R\n",
      "RT @BankofAmerica: These @SpecialOlympics athletes inspire us all. Watch them #PickUpHope for a more inclusive world at the @2018USAGames!…\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t…\n",
      "RT @MartySmithESPN: Sunday, the @SpecialOlympics #UnifiedChallenge pairs corporate executives from @CocaCola @Starbucks @Microsoft @BankofA…\n",
      "My #Hope is [Edit this tweet and write your own message of hope here] @2018USAGames @SpecialOlympics @BankofAmerica #PickUpHope\n",
      "RT @BankofAmerica: Follow these @SpecialOlympics athletes on their journey to @2018USAGames! When we #PickUpHope, hope picks us up even hig…\n",
      "@BankofAmerica always has some shit going on with them WTF\n",
      "RT @BankofAmerica: These brothers take teamwork to a new level as @SpecialOlympics athletes. Wish them luck at the @2018USAGames. https://t…\n",
      "@BankofAmerica Um I’ve been waiting to connect with a representative for almost an hour and a half....... CAN SOMEO… https://t.co/mb0EREx1p8\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @BankofAmerica: We work better together. Follow us to learn about the organizations we partner with to make change happen. https://t.co/…\n",
      "@BankofAmerica it literally took me this long and multiple phone calls from multiple phones to get through your ivr to get my card unlocked\n",
      "RT @TheGabbieShow: Pay Back a Friend Day is today so get your phones ready! #FriendsAgain #ad @BofA_Tips https://t.co/c6wCmkfP30 https://t.…\n",
      "RT @Johannes_Ernst: Hey @BankofAmerica, your privacy notice reminds me just how disregarded I feel as a customer. Obviously I don't want yo…\n",
      "@BankofAmerica I have been sitting at this ATM now for 30 min waiting on your IVR because your stupid ATM triggered a fraud alert on my card\n",
      "@BankofAmerica Why are your ATMs so slow, your IVR's so retarded, and your text notifications so late\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "Hey @BankofAmerica, your privacy notice reminds me just how disregarded I feel as a customer. Obviously I don't wan… https://t.co/zdCr0DVEi1\n",
      "RT @BankofAmerica: .@SpecialOlympics has changed the lives of two of our employees who are competing at the @2018USAgames #PickUpHope https…\n",
      "RT @barlowshell: Meet Devon and Ryan from the Arizona #SOCheer Squad! @BankofAmerica @2018USAGames #PickUpHope https://t.co/3y9lIxf78D\n",
      "@BankofAmerica I’ve been on hold for 40 min. Am I a valued customer or what?\n",
      "RT @BankofAmerica: Follow these @SpecialOlympics athletes on their journey to @2018USAGames! When we #PickUpHope, hope picks us up even hig…\n",
      "Really, @bankofamerica @bofa_help ? #Firefox https://t.co/K0aqnooELI\n",
      "RT @genderlensinv: Interview with #impinv &amp; #genderlensinv pioneer @jvbrug https://t.co/1XB63YYDb3 @RobbReport @BankofAmerica @MerrillLynch…\n",
      "Team @BankofAmerica @2018USAGames we all cheer you on!!! https://t.co/UvcmKsGYGK\n",
      "RT @barlowshell: Meet Devon and Ryan from the Arizona #SOCheer Squad! @BankofAmerica @2018USAGames #PickUpHope https://t.co/3y9lIxf78D\n",
      "Hey @BankofAmerica I’ve been on hold for over an hour trying to report fraud on my bank account... think someone co… https://t.co/GAkI2mA8y0\n",
      "RT @xlm_usd: Standing in line at @BankofAmerica , ridiculous. We need this gone from our lives. Banks fleece us by charging us ridiculous f…\n",
      "@MelRobsings @BankofAmerica Oooh thank you! I’ll do some research\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @PromiseFX: This is for all Americans who dislike #XRP.\n",
      "\n",
      "Both #Ripple and #XRP are founded by Americans. Both could be Americans next bi…\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "@BankofAmerica I really dislike that in a urgent matter my only options of help is speaking with a automated suppor… https://t.co/RwZkdrNR3r\n",
      "@BankofAmerica getting a few scam emails asking for my BoA account information\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @BankofAmerica: These @SpecialOlympics athletes inspire us all. Watch them #PickUpHope for a more inclusive world at the @2018USAGames!…\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "@BankofAmerica Our kids are now going with out food or diapers till Monday. We are reaching to our attorney and let… https://t.co/VuofoJ8acz\n",
      "@BankofAmerica We are reporting you to the OCC, BBB We opened a new account with you all and two weeks later after… https://t.co/6l1W0s3Kek\n",
      "RT @barlowshell: Meet Devon and Ryan from the Arizona #SOCheer Squad! @BankofAmerica @2018USAGames #PickUpHope https://t.co/3y9lIxf78D\n",
      "RT @genderlensinv: Interview with #impinv &amp; #genderlensinv pioneer @jvbrug https://t.co/1XB63YYDb3 @RobbReport @BankofAmerica @MerrillLynch…\n",
      "@StephenAmell @BankofAmerica Glad to know I'm not the only one who hates this. We were moving across country and de… https://t.co/Q7DPnA0ePI\n",
      "@Dodgers @ChuckyHustle818 @BankofAmerica @YasielPuig Wassa matta...ChapStick wouldn't step up???\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @GettyMuseum: Thank you, @BankofAmerica, for your support of #PSTLALA! https://t.co/3SZiXEo4G6\n",
      "@AntonGates @AmericanExpress @BankofAmerica @Mastercard @AntonGates We’re not here right now but we’ll reply when w… https://t.co/7zFoshG4I5\n",
      "I attempted a major purchase with my @AmericanExpress Plum card for 3hrs and received declines. How am I supposed t… https://t.co/yq60xWnpHp\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "New terms and conditions from @BankofAmerica: if there is something wrong with a transactions, there’s no point in… https://t.co/ChDfdF7oav\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @BankofAmerica: @Doewife “The Veneer of Civilization” of #VietnamWarPBS airs tonight @ 8p ET. Reply #stop to unsubscribe.\n",
      "https://t.co/r…\n",
      "@johnbohnenkamp @Dodgers @BankofAmerica cool idea!\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "RT @Dodgers: “Puig your friend, not your financial advisor.”\n",
      "\n",
      "Tonight’s Puigy Bank giveaway is presented by @BankofAmerica! #Dodgers https:…\n",
      "So exciting, we are cheering for you Tyler! @SpecialOlympics. #PickUpHope https://t.co/EWy1rxHJQA\n"
     ]
    }
   ],
   "source": [
    "for i in tweepy.Cursor(api.search, q='bankofamerica', lang = 'en', full_text=True).items(100):\n",
    "    print(i._json['text'])\n",
    "    #print(myStreamListener.processTweet(i._json['text']), end='\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also apply the preprocessing steps and obtain the feature vectors for the crawled twitter data.\n",
    "Classify the crawled tweets by passing its feature vector to the trained classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
